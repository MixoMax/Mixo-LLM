{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers     # only for the tokenizer\n",
    "import tensorflow as tf\n",
    "import jsonlines\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(\"kittn/mistral-7B-v0.1-hf\")\n",
    "\n",
    "def txt_to_tokens(txt: str) -> list[int]:\n",
    "    return tokenizer(txt, return_tensors=\"tf\").input_ids.numpy().tolist()[0]\n",
    "\n",
    "def tokens_to_txt(tokens: list[int]) -> str:\n",
    "    return tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "n_to_load = 1000\n",
    "with jsonlines.open(\"./data/train.jsonl\") as reader:\n",
    "    for i, obj in enumerate(reader):\n",
    "        if i >= n_to_load:\n",
    "            break\n",
    "        texts.append(\n",
    "            (obj[\"prompt\"], obj[\"text\"])\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 44.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for prompt, text in tqdm(texts):\n",
    "    prompt_tokens = txt_to_tokens(prompt)\n",
    "    text_tokens = txt_to_tokens(text)\n",
    "\n",
    "    for i in range(len(text_tokens) - 1):\n",
    "        X.append(prompt_tokens + text_tokens[:i])\n",
    "        Y.append(text_tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "        n_input_size: int,\n",
    "        n_layers: int,\n",
    "        n_hidden_size: int\n",
    "        ) -> tf.keras.Model:\n",
    "    \n",
    "    input_shape = (n_input_size,)\n",
    "    hidden_size = (n_hidden_size, n_hidden_size)\n",
    "    output_shape = (n_input_size,)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(n_hidden_size, activation=\"relu\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(n_input_size, activation=\"softmax\"))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: tf.keras.Model, x_train: list[list[int]], y_train: list[int], n_epochs: int, batch_size: int, lr: float):\n",
    "    # x_train: list of tokenized text\n",
    "    # y_train: list of the next token in the text\n",
    "\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optim, loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "    for _ in tqdm(range(n_epochs)):\n",
    "        model.fit(x_train, y_train, batch_size=batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: tf.keras.Model, txt: str, n: int) -> str:\n",
    "    tokens_in = txt_to_tokens(txt)\n",
    "    tokens_out = []\n",
    "    for _ in range(n):\n",
    "        tokens_in = model.predict(tokens_in)\n",
    "        tokens_out.append(tokens_in)\n",
    "    return tokens_to_txt(tokens_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_size = 512\n",
    "n_layers = 24\n",
    "n_hidden_size = 2048\n",
    "lr = 6e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              1050624   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,615,808\n",
      "Trainable params: 98,615,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = get_model(n_input_size, n_layers, n_hidden_size)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(model, X, Y, n_epochs=1, batch_size=32, lr=lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
